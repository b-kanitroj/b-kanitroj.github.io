Country/Region,Name/Developer,Release Year,Base,Base Model,Languages Used,Training Data Source,Smallest Parameters,Largest Parameters,"Open Source (1 = Yes, 0 = No)",Benchmarking & Performance,Challenges
Regional,SEA-Lion v2 / AI Singapore,2024,LLaMA,Llama 3,"English, Indonesian, Thai, Vietnamese, Tamil","LLaMA-3 8B CPT SEA-LIONv2, 48B tokens"," 8,030,000,000 "," 8,030,000,000 ",1,"Outperformed Meta-Llama across SEA languages, except for Tamil",Focus on SEA languages may limit broader performance
Regional,Sailor / Sea AI Lab & SUTD,2024,Qwen,Qwen 1.5,"English, Chinese, Vietnamese, Thai, Indonesian, Malay, Lao","CC100, MADLAD-400, SlimPajama, SkyPile, Wikipedia"," 500,000,000 "," 7,000,000,000 ",1,"Strong on SEA languages, superior in XQuAD and TydiQA",Struggles with option bias and vocabulary expansion
Regional,"SeaLLM3 / DAMO Academy, Alibaba",2024,Qwen,Qwen2,"English, Chinese, Indonesian, Vietnamese, Thai, etc.","Wikipedia, textbooks, CC-News, MADLAD-400"," 7,000,000,000 "," 7,000,000,000 ",1,"Top performance in M3Exam, MGSM, SeaBench, Flores-200",Data scarcity for low-resource languages
Indonesia,Cendol / INDO NLP Initiative,2024,LLaMA,"LLaMA-2, mT5",Indonesian and 18 local languages,"Indonesian Wikipedia, NusaCrowd, WikiHow, Malaysian Wikipedia"," 300,000,000 "," 13,000,000,000 ",1,20% improvement in NLP tasks,Generalization to unseen tasks
Indonesia,Compass / Shopee LLM Team,2024,LLaMA,LLaMA,"English, Chinese, Indonesian","Common Crawl, C4, Wikipedia, WebText"," 7,000,000,000 "," 7,000,000,000 ",0,Outperformed models like Vicuna-7b-v1.5 in SEA languages,Limited data for low-resource languages
Malaysia,MaLLaM / Mesolitica,2024,Trained from scratch,Trained from scratch,Malay,"Malay Wikipedia, government docs, social media, research papers"," 1,100,000,000 "," 5,000,000,000 ",1,"Competitive in zero-shot/few-shot settings, good performance in Malay language","Smaller dataset, potential biases in linguistic representation"
Thailand,THaLLE / KBTG Labs,2024,Qwen,Qwen2-7B-Instruct,"English, plans for Thai",CFA exam questions (2009-2019)," 8,000,000,000 "," 8,000,000,000 ",1,High performance on CFA exams,Limited in non-financial tasks
Thailand,OpenThaiGPT / AI Entrepreneurs Association of Thailand,2024,LLaMA,LLaMA-2,Thai,"65 billion Thai words, over 1M Thai instruction examples"," 7,000,000,000 "," 70,000,000,000 ",1,Best scores in Thai language exams,N/A
Thailand,WangchanLion / PyThaiNLP & VISTEC-depa AI Research Institute,2024,SEA-LION,SEA-LION,"Thai, English",Thai-English datasets for instruction-following," 7,000,000,000 "," 7,000,000,000 ",1,Outperforms OpenThaiGPT in reading comprehension tasks,Shorter answers with less context
Vietnamese,LaVy / Hanoi University of Science and Technology,2024,LLaVA,LLaVA,Vietnamese,"VinAI Translate, Google Translate, synthetic data with images"," 7,000,000,000 "," 7,000,000,000 ",1,Superior in Vietnamese visual language tasks,Occasional hallucinations
Vietnamese,Vi-Mistral-X / AgileSoDA,2024,Mistral,Mistral,Vietnamese,CulturaX multilingual dataset," 7,000,000,000 "," 7,000,000,000 ",1,Outperforms existing Vietnamese LLMs in text generation,N/A
Regional,SEA-Lion v1 / AI Singapore,2023,Trained from scratch,Trained from scratch,"English, Bahasa Indonesia, Thai, Vietnamese, Tamil",SEA-LION-PILE (1 trillion tokens), - , - ,1,"SEA-Lion outperformed in regional tasks, sustainable for SEA languages",Resource-intensive to train from scratch
Regional,"SeaLLM / DAMO Academy, Alibaba",2023,LLaMA,"Llama-2, Mistral-7B, Gemma-7B","Thai, Vietnamese, Indonesian, Chinese, Khmer, Lao, etc.","Common Crawl, Wikipedia, scholarly publications"," 7,000,000,000 "," 13,000,000,000 ",1,Outperformed ChatGPT-3.5 in non-Latin SEA languages,"Limited to 9 languages, hallucinations in Burmese and Lao"
Thailand,Typhoon / SCB 10X AI Team,2023,Mistral,Mistral-7B,"Thai, English","Common Crawl, MC4, OSCAR"," 7,000,000,000 "," 7,000,000,000 ",1,"Outperformed Thai models, efficient in Thai text",Potential hallucinations and inappropriate responses
Vietnamese,PhoGPT / VinAI Research,2023,Trained from scratch,Trained from scratch,Vietnamese,102 billion tokens," 3,700,000,000 "," 3,700,000,000 ",1,High accuracy on ViTruthfulQA,"Struggles with reasoning, coding, and math"
Vietnamese,VinaLLaMA / Virtual Interactive,2023,LLaMA,LLaMA-2,"Vietnamese, English","Vietnamese literature, news, synthetic data"," 2,700,000,000 "," 7,000,000,000 ",1,"State-of-the-art in VLSP, VMLU benchmarks","English proficiency not as strong, reliance on synthetic data"
Vietnamese,Vietcuna / Virtual Interactive,2023,BLOOMZ,BLOOMZ,Vietnamese,"Public news (VnExpress, Zing News)"," 3,000,000,000 "," 7,000,000,000 ",1,Details pending,N/A
Indonesia,"Sundanese GPT-2 / Wilson Wongso, et al.",2022,GPT-2,GPT-2,Sundanese,"Wikipedia, OSCAR, CC-100, C4"," 124,000,000 "," 124,000,000 ",1,Good performance in language generation and emotion classification,"Small pre-training corpus, potential biases"
Indonesia,"SundaBERT / Wilson Wongso, et al.",2022,BERT,BERT,Sundanese,"Wikipedia, OSCAR"," 110,000,000 "," 110,000,000 ",1,N/A,N/A
Indonesia,IndoBERT / University of Melbourne & Queensland,2020,BERT,BERT,Indonesian,"Indonesian Wikipedia, Kompas, Tempo, Liputan6"," 124,000,000 "," 124,000,000 ",1,State-of-the-art in INDOLEM benchmark,"Limited to Indonesian, underperforms in cross-lingual tasks"
Vietnamese,PhoBERT / VinAI Research,2020,BERT,BERT,Vietnamese,"Vietnamese corpus (Wikipedia, news)"," 135,000,000 "," 370,000,000 ",1,State-of-the-art in Vietnamese NLP tasks,"Parsing challenges, smaller data size"